{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello MP1!\n"
     ]
    }
   ],
   "source": [
    "print('Hello MP1!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries used for the project\n",
    "1. scikit-learn\n",
    "2. gensim\n",
    "3. nltk libraries\n",
    "4. numpy\n",
    "5. pandas\n",
    "6. matplotlib.pyplot\n",
    "7. json\n",
    "8. gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation & Analysis (5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Load the dataset. You can use `gzip.open` and `json.load` to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "dataset = gzip.open('goemotions.json.gz')\n",
    "dataset_json = json.load(dataset)\n",
    "\n",
    "# Close the gz dataset once your finished loading the data as a json object\n",
    "dataset.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. (5pts) Extract the posts and the 2 sets of labels (emotion and sentiment), then plot the distribution\n",
    "of the posts in each category and save the graphic (a histogram or pie chart) in pdf. Do this for both\n",
    "the emotion and the sentiment categories. You can use `matplotlib.pyplot` and `savefig` to do this.\n",
    "This pre-analysis of the dataset will allow you to determine if the classes are balanced, and which\n",
    "metric is more appropriate to use to evaluate the performance of your classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "numpy_dataset = np.array(dataset_json)\n",
    "\n",
    "# Get column only for emotion and sentiment\n",
    "emotion_dataset_col = numpy_dataset[:, 1]\n",
    "sentiment_dataset_col = numpy_dataset[:, 2]\n",
    "\n",
    "# Count the number of times each value appears\n",
    "emotion_count = Counter(emotion_dataset_col)\n",
    "sentiment_count = Counter(sentiment_dataset_col)\n",
    "\n",
    "# Save the data values as a histogram\n",
    "plt.hist(emotion_count.values())\n",
    "plt.savefig('emotions_graph')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.hist(sentiment_count.values())\n",
    "plt.savefig('sentiment_graph')\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Words as Features (35pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. □ (5pts) Process the dataset using `feature_extraction.text.CountVectorizer` to extract tokens/words\n",
    "and their frequencies. Display the number of tokens (the size of the vocabulary) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['That game hurt.' \"You do right, if you don't care then fuck 'em!\"\n",
      " 'Man I love reddit.' ...\n",
      " 'Well when you’ve imported about a gazillion of them I or your country it’s gets serious.'\n",
      " 'That looks amazing'\n",
      " \"The FDA has plenty to criticize. But like here, it's usually criticized horribly off base. It needs to grow some balls and actually enforce things. \"]\n",
      "Number of features (tokens in the vocabulary) = 30449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Phrases are in the first column of the dataset\n",
    "phrases = numpy_dataset[:, 0]\n",
    "print(phrases)\n",
    "\n",
    "# Process the dataset\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# X value is the processed_dataset\n",
    "X = vectorizer.fit_transform(phrases)\n",
    "# print(X.toarray())\n",
    "# print(processed_dataset[:100, :100].toarray())\n",
    "\n",
    "# Print the size of the vocabulary (number of tokens)\n",
    "# This is done by getting the size of the array(the columns will be the number of features, words in the vocabulary)\n",
    "# Can also be done by getting the length of vectorizer.get_feature_names_out()\n",
    "print(\"Number of features (tokens in the vocabulary) =\",\n",
    "      len(vectorizer.get_feature_names_out()))\n",
    "# print(\"Number of features (tokens in the vocabulary) =\",\n",
    "#       X.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. □ (2pts) Split the dataset into 80% for training and 20% for testing. For this, you can use `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set = 137456\n",
      "Size of testing set = 34364\n",
      "['disapproval' 'neutral' 'realization' ... 'admiration' 'neutral'\n",
      " 'admiration']\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "training_dataset, testing_dataset = train_test_split(\n",
    "    numpy_dataset, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Split the X (vectorizer matrix class)\n",
    "training_X, testing_X = train_test_split(X, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Print the size of both datasets\n",
    "print(\"Size of training set =\", training_dataset.shape[0])\n",
    "print(\"Size of testing set =\", testing_dataset.shape[0])\n",
    "print(training_dataset[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Train and test the following classifiers, for both the emotion and the sentiment classification, using\n",
    "word frequency as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.1. □ (3pts) **Base-MNB**: a Multinomial Naive Bayes Classifier `(naive_bayes.MultinomialNB.html)`\n",
    "with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'optimism' ... 'neutral' 'neutral' 'neutral']\n",
      "['positive' 'neutral' 'neutral' ... 'ambiguous' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Create the object classifiers for both emotions and sentiments\n",
    "emotions_classifier_mb = MultinomialNB()\n",
    "sentiment_classifier_mb = MultinomialNB()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_mb.fit(X=training_X,\n",
    "                  y=training_dataset[:, 1])\n",
    "sentiment_classifier_mb.fit(X=training_X,\n",
    "                  y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction = emotions_classifier_mb.predict(X=testing_X)\n",
    "print(emotion_prediction)\n",
    "sentiment_prediction = sentiment_classifier_mb.predict(X=testing_X)\n",
    "print(sentiment_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.2. □ (3pts) **Base-DT:** a Decision Tree `(tree.DecisionTreeClassifier)` with the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.3. □ (3pts) **Base-MLP:** a Multi-Layered Perceptron `(neural network.MLPClassifier)` with the\n",
    "default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.4. □ (3pts) **Top-MNB:** a better performing Multinomial Naive Bayes Classifier found using `GridSearchCV`.\n",
    "The gridsearch will allow you to find the best combination of hyper-parameters, as determined\n",
    "by the evaluation function that you have determined in step 1.3. The only hyper-parameter that\n",
    "you will experiment with is `alphafloat` with values 0.5, 0 and 2 other values of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.5. □ (3pts) **Top-DT:** a better performing Decision Tree found using `GridSearchCV.` The hyperparameters\n",
    "that you will experiment with are:\n",
    "  * `criterion:` gini or entropy\n",
    "  * `max depth:` 2 different values of your choice\n",
    "  * `min samples split:` 3 different values of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.6. □ (3pts) **Top-MLP:** a better performing Multi-Layered Perceptron found using GridSearchCV.\n",
    "The hyper-parameters that you will experiment with are:\n",
    "    * `activation:` sigmoid, tanh, relu and identity\n",
    "    * 2 network architectures of your choice: for eg, 2 hidden layers with 30+50 nodes and 3 hidden\n",
    "layers with 10 + 10 + 10\n",
    "    * `solver:` Adam and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. □ (5pts) For each of the 6 classifiers above and each of the classification tasks (emotion or sentiment),\n",
    "produce and save the following information in a file called `performance`:\n",
    "* a string clearly describing the model (e.g. the model name + hyper-parameter values) and the\n",
    "classification task (emotion or sentiment)\n",
    "* the confusion matrix – use `metrics.confusion_matrix`\n",
    "* the precision, recall, and F1-measure for each class, and the accuracy, macro-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5. □ (7.5pts) **Do your own exploration:** Do only one of the following, depending on your own interest:\n",
    "* Use tf-idf instead of word frequencies and redo all substeps of 2.3 above – you can use `TfidfTransformer`\n",
    "for this. Display the results of this experiment.\n",
    "* Remove stop words and redo all substeps of 2.3 above – you can use the parameter of `CountVectorizer`\n",
    "for this. Display the results of this experiment.\n",
    "* Play with `train_test_split` in order have different splits of 80% training, 20% test sets and\n",
    "different sizes of training sets and redo all substeps of 2.3 above. Show and explain how the\n",
    "performance of your models vary depending on the training/test sets are used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90e4f055ace36640af0392f50413c0cd35ea54a1eb2fa59636646015dc42e79c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
