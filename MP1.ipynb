{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello MP1!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported libraries used for the project\n",
    "1. jupiter\n",
    "2. scikit-learn\n",
    "3. gensim\n",
    "4. nltk\n",
    "5. numpy\n",
    "6. pandas\n",
    "7. matplotlib\n",
    "\n",
    "`conda install jupyter scikit-learn gensim nltk numpy pandas matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation & Analysis (5pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Load the dataset. You can use `gzip.open` and `json.load` to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "dataset = gzip.open('goemotions.json.gz')\n",
    "dataset_json = json.load(dataset)\n",
    "\n",
    "# Close the gz dataset once your finished loading the data as a json object\n",
    "dataset.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. (5pts) Extract the posts and the 2 sets of labels (emotion and sentiment), then plot the distribution\n",
    "of the posts in each category and save the graphic (a histogram or pie chart) in pdf. Do this for both\n",
    "the emotion and the sentiment categories. You can use `matplotlib.pyplot` and `savefig` to do this.\n",
    "This pre-analysis of the dataset will allow you to determine if the classes are balanced, and which\n",
    "metric is more appropriate to use to evaluate the performance of your classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "numpy_dataset = np.array(dataset_json)\n",
    "\n",
    "# Get column only for emotion and sentiment\n",
    "emotion_dataset_col = numpy_dataset[:, 1]\n",
    "sentiment_dataset_col = numpy_dataset[:, 2]\n",
    "\n",
    "# Count the number of times each value appears\n",
    "emotion_count = Counter(emotion_dataset_col)\n",
    "sentiment_count = Counter(sentiment_dataset_col)\n",
    "\n",
    "\n",
    "plt.pie(emotion_count.values(), None, emotion_count.keys())\n",
    "plt.savefig('emotions_pie_chart')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "plt.pie(sentiment_count.values(), None, sentiment_count.keys())\n",
    "plt.savefig('sentiment_pie_chart')\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Words as Features (35pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used this to speed up the time for making classification but its not necesarry.\n",
    "# import torch\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(\"Device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. □ (5pts) Process the dataset using `feature_extraction.text.CountVectorizer` to extract tokens/words\n",
    "and their frequencies. Display the number of tokens (the size of the vocabulary) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Phrases are in the first column of the dataset\n",
    "phrases = numpy_dataset[:, 0]\n",
    "\n",
    "# Process the dataset\n",
    "vectorizer_emotions = CountVectorizer()\n",
    "\n",
    "# X value is the processed_dataset\n",
    "X_emotions = vectorizer_emotions.fit_transform(phrases)\n",
    "\n",
    "print(\"Number of features (tokens in the vocabulary) =\",\n",
    "      len(vectorizer_emotions.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = numpy_dataset[:, 1]\n",
    "\n",
    "emotions_and_phrases = phrases.copy()\n",
    "\n",
    "for count, i in enumerate(phrases):\n",
    "    emotions_and_phrases[count] = i + \" \" + emotions[count]\n",
    "\n",
    "vectorizer_sentiments = CountVectorizer()\n",
    "X_sentiments = vectorizer_sentiments.fit_transform(emotions_and_phrases)\n",
    "\n",
    "print(\"Number of features (tokens in the vocabulary) including emotions =\",\n",
    "      len(vectorizer_sentiments.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. □ (2pts) Split the dataset into 80% for training and 20% for testing. For this, you can use `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "training_dataset, testing_dataset = train_test_split(\n",
    "    numpy_dataset, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Split the feature vector of emotions\n",
    "training_X_emotions, testing_X_emotions = train_test_split(\n",
    "    X_emotions, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Split the feature vector of sentiments\n",
    "training_X_sentiments, testing_X_sentiments = train_test_split(\n",
    "    X_sentiments, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Print the size of both datasets\n",
    "print(\"Size of training set =\", training_dataset.shape[0])\n",
    "print(\"Size of testing set =\", testing_dataset.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. Train and test the following classifiers, for both the emotion and the sentiment classification, using\n",
    "word frequency as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.1. □ (3pts) **Base-MNB**: a Multinomial Naive Bayes Classifier `(naive_bayes.MultinomialNB.html)`\n",
    "with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create the object classifiers for emotions\n",
    "emotions_classifier_mb = MultinomialNB()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_mb.fit(X=training_X_emotions,\n",
    "                           y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction_mb = emotions_classifier_mb.predict(X=testing_X_emotions)\n",
    "print(emotion_prediction_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for Multinomial classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.3.1\", \"w\")\n",
    "performance_file.write(\n",
    "    \"-----Emotions classification (Multinomial Naive Bayes)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_mb.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object classifiers for sentiments\n",
    "sentiment_classifier_mb = MultinomialNB()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "sentiment_classifier_mb.fit(X=training_X_sentiments,\n",
    "                            y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "sentiment_prediction_mb = sentiment_classifier_mb.predict(\n",
    "    X=testing_X_sentiments)\n",
    "print(sentiment_prediction_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.3.1\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Multinomial Naive Bayes)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiment_classifier_mb.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiment_prediction_mb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiment_prediction_mb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.2. □ (3pts) **Base-DT:** a Decision Tree `(tree.DecisionTreeClassifier)` with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the object classifiers for emotions\n",
    "emotions_classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_dt.fit(X=training_X_emotions,\n",
    "                           y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction_dt = emotions_classifier_dt.predict(X=testing_X_emotions)\n",
    "print(emotion_prediction_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for DecisionTree classification\n",
    "\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.3.2\", \"w\")\n",
    "performance_file.write(\"-----Emotions classification (Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_dt.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_dt)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_dt, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object classifiers for sentiments\n",
    "sentiment_classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "sentiment_classifier_dt.fit(X=training_X_sentiments,\n",
    "                            y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "sentiment_prediction_dt = sentiment_classifier_dt.predict(\n",
    "    X=testing_X_sentiments)\n",
    "print(sentiment_prediction_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.3.2\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiment_classifier_dt.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiment_prediction_dt)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiment_prediction_dt, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.3. □ (3pts) **Base-MLP:** a Multi-Layered Perceptron `(neural network.MLPClassifier)` with the\n",
    "default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create the object classifiers for emotions\n",
    "emotions_classifier_mlp = MLPClassifier(verbose=True,max_iter=1)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_mlp.fit(X=training_X_emotions, y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction_mlp = emotions_classifier_mlp.predict(X=testing_X_emotions)\n",
    "print(emotion_prediction_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2.4 for MLP classification\n",
    "\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.3.3\", \"w\")\n",
    "performance_file.write(\"-----Emotions classification (multi layer perceptron)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_mlp.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the object classifiers for sentiments\n",
    "sentiment_classifier_mlp = MLPClassifier(verbose=True,max_iter=1)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "sentiment_classifier_mlp.fit(X=training_X_sentiments, y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "sentiment_prediction_mlp = sentiment_classifier_mlp.predict(X=testing_X_sentiments)\n",
    "\n",
    "print(sentiment_prediction_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.3.3\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Multi layer perceptron)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiment_classifier_mlp.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiment_prediction_mlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiment_prediction_mlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.4. □ (3pts) **Top-MNB:** a better performing Multinomial Naive Bayes Classifier found using `GridSearchCV`.\n",
    "The gridsearch will allow you to find the best combination of hyper-parameters, as determined\n",
    "by the evaluation function that you have determined in step 1.3. The only hyper-parameter that\n",
    "you will experiment with is `alphafloat` with values 0.5, 0 and 2 other values of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'alpha': [0, 0.5, 1.0, 5.0]}\n",
    "\n",
    "# emotions gridsearch for Top Multinomial Naive Bayes\n",
    "emo_top_mnb_gridsearch = GridSearchCV(emotions_classifier_mb, param_grid=hyperparam)\n",
    "emo_top_mnb_gridsearch.fit(X=training_X_emotions, y=training_dataset[:, 1])\n",
    "emo_prediction_tmb = emo_top_mnb_gridsearch.predict(X=testing_X_emotions)\n",
    "print(emo_prediction_tmb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for Top Multinomial Naive Bayes classification with GridSearchCV (Emotions)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.3.4\", \"w\")\n",
    "performance_file.write(\"-----Emotions classification (Top Multinomial Naive Bayes with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Emotions hyperparamenters = {emo_top_mnb_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=testing_dataset[:, 1], y_pred=emo_prediction_tmb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=testing_dataset[:, 1], y_pred=emo_prediction_tmb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiments gridsearch for Top Multinomial Naive Bayes\n",
    "sen_top_mnb_gridsearch = GridSearchCV(sentiment_classifier_mb, param_grid=hyperparam)\n",
    "sen_top_mnb_gridsearch.fit(X=training_X_sentiments, y=training_dataset[:, 2])\n",
    "sen_prediction_tmb = sen_top_mnb_gridsearch.predict(X=testing_X_sentiments)\n",
    "print(sen_prediction_tmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for Top Multinomial Naive Bayes classification with GridSearchCV (Sentiment)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.3.4\", \"a\")\n",
    "performance_file.write(\"-----Sentiment classification (Top Multinomial Naive Bayes with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Sentiment hyperparamenters = {sen_top_mnb_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=testing_dataset[:, 2], y_pred=sen_prediction_tmb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=testing_dataset[:, 2], y_pred=sen_prediction_tmb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.5. □ (3pts) **Top-DT:** a better performing Decision Tree found using `GridSearchCV.` The hyperparameters\n",
    "that you will experiment with are:\n",
    "  * `criterion:` gini or entropy\n",
    "  * `max depth:` 2 different values of your choice\n",
    "  * `min samples split:` 3 different values of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# apply hyper parameters\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [2, 4], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# create objects classifier with grid search\n",
    "grid_search_emotion_classifier = GridSearchCV(\n",
    "    emotions_classifier_dt, param_grid)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "grid_search_emotion_classifier.fit(\n",
    "    X=training_X_emotions, y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "grid_search_emotion_predict = grid_search_emotion_classifier.predict(\n",
    "    X=testing_X_emotions)\n",
    "print(grid_search_emotion_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for gridsearch Dt classification\n",
    "\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.3.5\", \"w\")\n",
    "performance_file.write(\"-----Emotions classification (Grid Search Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {grid_search_emotion_classifier.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=grid_search_emotion_predict)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=grid_search_emotion_predict, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create objects classifier with grid search\n",
    "grid_search_sentiment_classifier = GridSearchCV(sentiment_classifier_dt, param_grid)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "grid_search_sentiment_classifier.fit(X=training_X_sentiments, y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "grid_search_sentiment_predict = grid_search_sentiment_classifier.predict(X=testing_X_sentiments)\n",
    "print(grid_search_sentiment_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.3.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Grid Search Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {grid_search_sentiment_classifier.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=grid_search_sentiment_predict)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=grid_search_sentiment_predict, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.3.6. □ (3pts) **Top-MLP:** a better performing Multi-Layered Perceptron found using GridSearchCV.\n",
    "The hyper-parameters that you will experiment with are:\n",
    "    * `activation:` sigmoid, tanh, relu and identity\n",
    "    * 2 network architectures of your choice: for eg, 2 hidden layers with 30+50 nodes and 3 hidden\n",
    "layers with 10 + 10 + 10\n",
    "    * `solver:` Adam and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'activation': ['sigmoid', 'tanh', 'relu', 'identity'],\n",
    "                'hidden_layer_sizes': [2, 3],\n",
    "                'solver': ['Adam', 'sgd']}\n",
    "\n",
    "emo_top_mlp_gridsearch = GridSearchCV(emotions_classifier_mlp, param_grid=hyperparam)\n",
    "emo_top_mlp_gridsearch.fit(X=training_X_emotions, y=training_dataset[:, 1])\n",
    "emo_prediction_tmlp = emo_top_mlp_gridsearch.predict(X=testing_X_emotions)\n",
    "print(emo_prediction_tmlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for Top Multi-Layered Percentron classification with GridSearchCV (Emotions)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.3.6\", \"w\")\n",
    "performance_file.write(\"-----Emotions classification (Top Multi-Layered Percentron with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Emotions hyperparamenters = {emo_top_mlp_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=testing_dataset[:, 1], y_pred=emo_prediction_tmlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=testing_dataset[:, 1], y_pred=emo_prediction_tmlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_top_mlp_gridsearch = GridSearchCV(emotions_classifier_mlp, param_grid=hyperparam)\n",
    "sen_top_mlp_gridsearch.fit(X=training_X_emotions, y=training_dataset[:, 2])\n",
    "sen_prediction_tmlp = sen_top_mlp_gridsearch.predict(X=testing_X_emotions)\n",
    "print(emo_prediction_tmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.4 for Top Multi-Layered Percentron classification with GridSearchCV (Sentiment)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Append Sentiment results\n",
    "performance_file = open(\"performance_2.3.6\", \"a\")\n",
    "performance_file.write(\"-----Sentiment classification (Top Multi-Layered Percentron with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Sentiment hyperparamenters = {sen_top_mlp_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=testing_dataset[:, 2], y_pred=sen_prediction_tmlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=testing_dataset[:, 2], y_pred=sen_prediction_tmlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. □ (5pts) For each of the 6 classifiers above and each of the classification tasks (emotion or sentiment),\n",
    "produce and save the following information in a file called `performance`:\n",
    "* a string clearly describing the model (e.g. the model name + hyper-parameter values) and the\n",
    "classification task (emotion or sentiment)\n",
    "* the confusion matrix – use `metrics.confusion_matrix`\n",
    "* the precision, recall, and F1-measure for each class, and the accuracy, macro-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5. □ (7.5pts) **Do your own exploration:** Do only one of the following, depending on your own interest:\n",
    "* Use tf-idf instead of word frequencies and redo all substeps of 2.3 above – you can use `TfidfTransformer`\n",
    "for this. Display the results of this experiment.\n",
    "* Remove stop words and redo all substeps of 2.3 above – you can use the parameter of `CountVectorizer`\n",
    "for this. Display the results of this experiment.\n",
    "* Play with `train_test_split` in order have different splits of 80% training, 20% test sets and\n",
    "different sizes of training sets and redo all substeps of 2.3 above. Show and explain how the\n",
    "performance of your models vary depending on the training/test sets are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option chosen: play with train_test_split (50%:50%)\n",
    "Step 1: change the training and test set sizes to 50% <br><br>\n",
    "\n",
    "<b>Hypothesis:\n",
    "we can assume this will have a net negative outcome \n",
    "since the training set is losing 30% of its testable material.\n",
    "Size of original training set = 137456 Size of original testing set = 34364\n",
    "Size of new training set = 85910 Size of new testing set = 85910</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_size = 0.5 # training size percentage\n",
    "te_size = 0.5 # testing size percentage\n",
    "\n",
    "# Split the dataset\n",
    "new_training_dataset, new_testing_dataset = train_test_split(\n",
    "    numpy_dataset, train_size = tr_size, test_size = te_size)\n",
    "\n",
    "# Split the feature vector of emotions\n",
    "new_training_X_emotions, new_testing_X_emotions = train_test_split(\n",
    "    X_emotions, train_size = tr_size, test_size = te_size)\n",
    "\n",
    "# Split the feature vector of sentiments\n",
    "new_training_X_sentiments, new_testing_X_sentiments = train_test_split(\n",
    "    X_sentiments, train_size = tr_size, test_size = te_size)\n",
    "\n",
    "# Print the size of both datasets\n",
    "print(\"Size of training set =\", new_training_dataset.shape[0])\n",
    "print(\"Size of testing set =\", new_testing_dataset.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 - 2.3.1 Redo Base-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create the object classifiers for emotions\n",
    "new_emotions_classifier_mb = MultinomialNB()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_emotions_classifier_mb.fit(X=new_training_X_emotions,\n",
    "                           y=new_training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_emotion_prediction_mb = new_emotions_classifier_mb.predict(X=new_testing_X_emotions)\n",
    "print(new_emotion_prediction_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenting Multinomial classification (Emotions & Sentiment)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Append Emotions results to a new performance document\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Emotions classification (Multinomial Naive Bayes)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {new_emotions_classifier_mb.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_emotion_prediction_mb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_emotion_prediction_mb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object classifiers for sentiments\n",
    "new_sentiment_classifier_mb = MultinomialNB()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_sentiment_classifier_mb.fit(X=new_training_X_sentiments,\n",
    "                            y=new_training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_sentiment_prediction_mb = new_sentiment_classifier_mb.predict(\n",
    "    X=new_testing_X_sentiments)\n",
    "print(new_sentiment_prediction_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results to a new performance document\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Multinomial Naive Bayes)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {new_sentiment_classifier_mb.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_sentiment_prediction_mb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_sentiment_prediction_mb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 - 2.3.2 Redo Base-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Create the object classifiers for emotions\n",
    "new_emotions_classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_emotions_classifier_dt.fit(X=new_training_X_emotions,\n",
    "                           y=new_training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_emotion_prediction_dt = new_emotions_classifier_dt.predict(X=new_testing_X_emotions)\n",
    "print(new_emotion_prediction_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenting DecisionTree classification (Emotions & Sentiment)\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Emotions classification (Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {new_emotions_classifier_dt.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_emotion_prediction_dt)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_emotion_prediction_dt, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object classifiers for sentiments\n",
    "new_sentiment_classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_sentiment_classifier_dt.fit(X=new_training_X_sentiments,\n",
    "                            y=new_training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_sentiment_prediction_dt = new_sentiment_classifier_dt.predict(\n",
    "    X=new_testing_X_sentiments)\n",
    "print(new_sentiment_prediction_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {new_sentiment_classifier_dt.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_sentiment_prediction_dt)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_sentiment_prediction_dt, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 - 2.3.3 Redo Base-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create the object classifiers for emotions\n",
    "new_emotions_classifier_mlp = MLPClassifier(verbose=True,max_iter=1)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_emotions_classifier_mlp.fit(X=training_X_emotions, y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_emotion_prediction_mlp = new_emotions_classifier_mlp.predict(X=new_testing_X_emotions)\n",
    "print(new_emotion_prediction_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenting MLPClassifier classification (Emotions & Sentiment)\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Emotions classification (multi layer perceptron)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {new_emotions_classifier_mlp.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_emotion_prediction_mlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_emotion_prediction_mlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object classifiers for sentiments\n",
    "new_sentiment_classifier_mlp = MLPClassifier(verbose=True,max_iter=1)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_sentiment_classifier_mlp.fit(X=new_training_X_sentiments, y=new_training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_sentiment_prediction_mlp = new_sentiment_classifier_mlp.predict(X=new_testing_X_sentiments)\n",
    "\n",
    "print(new_sentiment_prediction_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Multi layer perceptron)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {new_sentiment_classifier_mlp.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_sentiment_prediction_mlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_sentiment_prediction_mlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 - 2.3.4 Redo Top-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'alpha': [0, 0.5, 1.0, 5.0]}\n",
    "\n",
    "# emotions gridsearch for Top Multinomial Naive Bayes\n",
    "new_emo_top_mnb_gridsearch = GridSearchCV(new_emotions_classifier_mb, param_grid=hyperparam)\n",
    "new_emo_top_mnb_gridsearch.fit(X=new_training_X_emotions, y=new_training_dataset[:, 1])\n",
    "new_emo_prediction_tmb = new_emo_top_mnb_gridsearch.predict(X=new_testing_X_emotions)\n",
    "print(new_emo_prediction_tmb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Documenting Top Multinomial Naive Bayes classification with GridSearchCV (Emotions)\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Emotions classification (Top Multinomial Naive Bayes with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Emotions hyperparamenters = {new_emo_top_mnb_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=new_testing_dataset[:, 1], y_pred=new_emo_prediction_tmb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=new_testing_dataset[:, 1], y_pred=new_emo_prediction_tmb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'alpha': [0, 0.5, 1.0, 5.0]}\n",
    "\n",
    "# sentiments gridsearch for Top Multinomial Naive Bayes\n",
    "new_sen_top_mnb_gridsearch = GridSearchCV(new_sentiment_classifier_mb, param_grid=hyperparam)\n",
    "new_sen_top_mnb_gridsearch.fit(X=new_training_X_sentiments, y=new_training_dataset[:, 2])\n",
    "new_sen_prediction_tmb = new_sen_top_mnb_gridsearch.predict(X=new_testing_X_sentiments)\n",
    "print(new_sen_prediction_tmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Documenting Top Multinomial Naive Bayes classification with GridSearchCV (Sentiment)\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Sentiment classification (Top Multinomial Naive Bayes with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Sentiment hyperparamenters = {new_sen_top_mnb_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=new_testing_dataset[:, 2], y_pred=new_sen_prediction_tmb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=new_testing_dataset[:, 2], y_pred=new_sen_prediction_tmb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 - 2.3.5 Redo Top-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# apply hyper parameters\n",
    "param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': [2, 4], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# create objects classifier with grid search\n",
    "new_grid_search_emotion_classifier = GridSearchCV(new_emotions_classifier_dt, param_grid)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_grid_search_emotion_classifier.fit(X=new_training_X_emotions, y=new_training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_grid_search_emotion_predict = new_grid_search_emotion_classifier.predict(X=new_testing_X_emotions)\n",
    "print(new_grid_search_emotion_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documenting for gridsearch Dt classification\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Emotions classification (Grid Search Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {new_grid_search_emotion_classifier.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_grid_search_emotion_predict)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 1], y_pred=new_grid_search_emotion_predict, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create objects classifier with grid search\n",
    "new_grid_search_sentiment_classifier = GridSearchCV(new_sentiment_classifier_dt, param_grid)\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "new_grid_search_sentiment_classifier.fit(X=new_training_X_sentiments, y=new_training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "new_grid_search_sentiment_predict = new_grid_search_sentiment_classifier.predict(X=new_testing_X_sentiments)\n",
    "print(new_grid_search_sentiment_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (Grid Search Decision Tree)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {new_grid_search_sentiment_classifier.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_grid_search_sentiment_predict)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=new_testing_dataset[:, 2], y_pred=new_grid_search_sentiment_predict, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 - 2.3.6 Redo Top-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'activation': ['sigmoid', 'tanh', 'relu', 'identity'],\n",
    "                'hidden_layer_sizes': [2, 3],\n",
    "                'solver': ['Adam', 'sgd']}\n",
    "# Create the object classifiers for emotions\n",
    "new_emo_top_mlp_gridsearch = GridSearchCV(emotions_classifier_mlp, param_grid=hyperparam)\n",
    "# Fit the model with new_training_X as X and columns of new_training_dataset as y\n",
    "new_emo_top_mlp_gridsearch.fit(X=new_training_X_emotions, y=new_training_dataset[:, 1])\n",
    "# Make predictions with new_testing_X as X\n",
    "new_emo_prediction_tmlp = new_emo_top_mlp_gridsearch.predict(X=new_testing_X_emotions)\n",
    "print(new_emo_prediction_tmlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Documenting Top Multi-Layered Percentron classification with GridSearchCV (Emotions)\n",
    "\n",
    "# Append Emotions results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Emotions classification (Top Multi-Layered Percentron with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Emotions hyperparamenters = {new_emo_top_mlp_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=new_testing_dataset[:, 1], y_pred=new_emo_prediction_tmlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=new_testing_dataset[:, 1], y_pred=new_emo_prediction_tmlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'activation': ['sigmoid', 'tanh', 'relu', 'identity'],\n",
    "                'hidden_layer_sizes': [2, 3],\n",
    "                'solver': ['Adam', 'sgd']}\n",
    "# Create the object classifiers for emotions\n",
    "new_sen_top_mlp_gridsearch = GridSearchCV(emotions_classifier_mlp, param_grid=hyperparam)\n",
    "# Fit the model with new_training_X as X and columns of new_training_dataset as y\n",
    "new_sen_top_mlp_gridsearch.fit(X=new_training_X_emotions, y=new_training_dataset[:, 2])\n",
    "# Make predictions with new_testing_X as X\n",
    "new_sen_prediction_tmlp = new_sen_top_mlp_gridsearch.predict(X=new_testing_X_emotions)\n",
    "print(new_emo_prediction_tmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Documenting Top Multi-Layered Percentron classification with GridSearchCV (Sentiment)\n",
    "\n",
    "# Append Sentiment results\n",
    "performance_file = open(\"performance_2.5\", \"a\")\n",
    "performance_file.write(\"-----Sentiment classification (Top Multi-Layered Percentron with GridSearchCV)-----\\n\")\n",
    "\n",
    "performance_file.write(f\"Sentiment hyperparamenters = {new_sen_top_mlp_gridsearch.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(y_true=new_testing_dataset[:, 2], y_pred=new_sen_prediction_tmlp)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(y_true=new_testing_dataset[:, 2], y_pred=new_sen_prediction_tmlp, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Verdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "We played with train_test_split using 2 different percentages.\n",
    "<br><br>\n",
    "The first split we used was 50% for the training set and 50% for the testing set.<br>\n",
    "This gave us a split of:<br>\n",
    "Size of new training set = 85910<br> Size of new testing set = 85910<br>\n",
    "We expected that the 30% drop in data for the training set would result in a less accurate reading when doing the testing but this we just not the case. As seen in the \"new_performace\" file that is produced when running the redone train_test_split, our hypothesis was wrong. The accuracy, precision, recall and f1-score barely changed if at all. This result created more questions than answering them. A possible issue that would explain these unusual results could be how the dataset is not a well-balanced dataset.\n",
    "<br><br>\n",
    "The second split we used was 20% for the training set and 80% for the testing set.<br>\n",
    "This gave us a split of:<br>\n",
    "Size of new training set = 34364<br> Size of new testing set = 137456<br>\n",
    "We decided to run the inverse of the original split since the 50:50 split did not yield the expected test results. This new split yielded some interesting results as well. As seen in the \"new_performance\" file the precision for overall lower than the original and 50:50 splits, which is reasonable to believe considering the training set is only 20% of the original dataset size. As for other values such as the f1-score and precision did not provide substancial evidence to prove that changing the split for this specific dataset would yield predictable results.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embeddings as Features (20pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. □ (0pts) Use `gensim.downloader.load` to load the `word2vec-google-news-300` pretrained embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase its the first time running\n",
    "# import nltk\n",
    "\n",
    "# nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "google_model = gensim.downloader.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. □ (2pts) Use the `tokenizer` from `nltk` to extract words from the Reddit posts. Display the number\n",
    "of tokens in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "\n",
    "\n",
    "phrase_token_vector = [nltk.tokenize.word_tokenize(i) for i in phrases]\n",
    "emotions_and_phrases_token_vector = [nltk.tokenize.word_tokenize(i) for i in emotions_and_phrases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token count in phrase token list\n",
    "token_count = 0\n",
    "for i in phrase_token_vector:\n",
    "    token_count += len(i)\n",
    "\n",
    "print(\"Number of Tokens in phrases=\", token_count)\n",
    "\n",
    "\n",
    "# Get the token count in phrase and emotion token list\n",
    "token_count = 0\n",
    "for i in emotions_and_phrases_token_vector:\n",
    "    token_count += len(i)\n",
    "\n",
    "print(\"Number of Tokens in phrases=\", token_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. □ (5pts) Compute the embedding of a Reddit post as the <u>average</u> of the embeddings of its words. If\n",
    "a word has no embedding in Word2Vec, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "\n",
    "mean_embedding_list_emotions = []\n",
    "for i in phrase_token_vector:\n",
    "    mean_embedding_list_emotions.append(google_model.get_mean_vector(i))\n",
    "\n",
    "mean_embedding_list_sentiments = []\n",
    "for i in emotions_and_phrases_token_vector:\n",
    "    mean_embedding_list_sentiments.append(google_model.get_mean_vector(i))\n",
    "\n",
    "\n",
    "# Test to get the average embedding for a phrase with index i\n",
    "i = 0\n",
    "print(\n",
    "    f\"The mean embedding for phrase: '{phrase_token_vector[i]}'\\n = \\n{mean_embedding_list_emotions[i]}\")\n",
    "\n",
    "# Test to get the average embedding for a pohrase and emotion with index i\n",
    "i = 0\n",
    "print(\n",
    "    f\"The mean embedding for phrase and emotion: '{emotions_and_phrases_token_vector[i]}'\\n = \\n{mean_embedding_list_sentiments[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. □ (3pts) Compute and display the overall hit rates of the training and test sets (i.e. the % of words\n",
    "in the Reddit posts for which an embedding is found in Word2Vec).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the tokens (to get the hit rate)\n",
    "training_phrase_token, testing_phrase_token = train_test_split(\n",
    "    phrase_token_vector, train_size=0.8, test_size=0.2)\n",
    "\n",
    "training_emotions_and_phrases_token, testing_emotions_and_phrases_token = train_test_split(\n",
    "    emotions_and_phrases_token_vector, train_size=0.8, test_size=0.2)\n",
    "\n",
    "\n",
    "# Split the mean embedding list for both eomtions and sentiments (the X values)\n",
    "training_X_emotions_emb, testing_X_emotions_emb = train_test_split(\n",
    "    mean_embedding_list_emotions, train_size=0.8, test_size=0.2)\n",
    "\n",
    "training_X_sentiments_emb, testing_X_sentiments_emb = train_test_split(\n",
    "    mean_embedding_list_sentiments, train_size=0.8, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit Rate for phrases training set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in training_phrase_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            google_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in training set (phrases) = {num_of_hits/total*100}%\")\n",
    "\n",
    "\n",
    "# Hit Rate for phrases testing set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in testing_phrase_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            google_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in testing set (phrases) = {num_of_hits/total*100}%\")\n",
    "\n",
    "# Hit Rate for phrases and emotions training set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in training_emotions_and_phrases_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            google_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in training set (phrases and emotions) = {num_of_hits/total*100}%\")\n",
    "\n",
    "\n",
    "# Hit Rate for phrases and emotions testing set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in testing_emotions_and_phrases_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            google_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in testing set (phrases and emotions) = {num_of_hits/total*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5. □ (3pts) **Train a Base-MLP:** a Multi-Layered Perceptron (`neural_network.MLPClassifier`) with\n",
    "the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# For emotions classification\n",
    "emotions_classifier_mlp_embedding = MLPClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_mlp_embedding.fit(X=training_X_emotions_emb,\n",
    "                                      y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction_mlp_embedding = emotions_classifier_mlp_embedding.predict(\n",
    "    X=testing_X_emotions_emb)\n",
    "print(emotion_prediction_mlp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Emotions results\n",
    "performance_file = open(\"performance_3.5\", \"w\")\n",
    "performance_file.write(\n",
    "    \"-----Emotions classification (google model) (Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_mlp_embedding.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp_embedding)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp_embedding, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sentiments classification\n",
    "sentiments_classifier_mlp_embedding = MLPClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "sentiments_classifier_mlp_embedding.fit(X=training_X_sentiments_emb,\n",
    "                                      y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "sentiments_prediction_mlp_embedding = sentiments_classifier_mlp_embedding.predict(\n",
    "    X=testing_X_sentiments_emb)\n",
    "print(sentiments_prediction_mlp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_3.5\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (google model) (Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiments_classifier_mlp_embedding.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_prediction_mlp_embedding)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_prediction_mlp_embedding, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6. □ (3pts) **Train a Top-MLP:** a better performing Multi-Layered Perceptron found with whatever\n",
    "hyperparameters you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# hyperparameter used in gridsearch\n",
    "hyperparam = {'activation': ['tanh', 'relu', 'identity'],\n",
    "                'hidden_layer_sizes': [2, 3],\n",
    "                'solver': ['Adam', 'sgd']}\n",
    "\n",
    "# For emotions classification\n",
    "emotions_classifier_top_mlp_gridsearch_emb = GridSearchCV(emotions_classifier_mlp_embedding, param_grid=hyperparam)\n",
    "emotions_classifier_top_mlp_gridsearch_emb.fit(X=training_X_emotions_emb, y=training_dataset[:, 1])\n",
    "emotions_classifier_prediction_tmlp_emb = emotions_classifier_top_mlp_gridsearch_emb.predict(X=testing_X_emotions_emb)\n",
    "print(emotions_classifier_prediction_tmlp_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Emotions results\n",
    "performance_file = open(\"performance_3.6\", \"w\")\n",
    "performance_file.write(\n",
    "    \"-----Emotions classification (google model) (TOP Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_top_mlp_gridsearch_emb.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotions_classifier_prediction_tmlp_emb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotions_classifier_prediction_tmlp_emb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sentiments classifications\n",
    "sentiments_classifier_top_mlp_gridsearch_emb = GridSearchCV(sentiments_classifier_mlp_embedding, param_grid=hyperparam)\n",
    "sentiments_classifier_top_mlp_gridsearch_emb.fit(X=training_X_sentiments_emb, y=training_dataset[:, 2])\n",
    "sentiments_classifier_prediction_tmlp_emb = sentiments_classifier_top_mlp_gridsearch_emb.predict(X=testing_X_emotions_emb)\n",
    "print(sentiments_classifier_prediction_tmlp_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_3.6\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (google model) (TOP Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiments_classifier_top_mlp_gridsearch_emb.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_classifier_prediction_tmlp_emb)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_classifier_prediction_tmlp_emb, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7. □ (2pts) Display the performance of your classifiers using `metrics.classification_report` and add\n",
    "these to your `performance` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See code after generating the classifications for both 3.5 and 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.8. □ (7.5pts) **Do your own exploration:** Rerun your best performing model but with 2 other English\n",
    "pretrained embedding models and compare the results. Many pre-trained embeddings are available\n",
    "on line (including in Gensim or at http://vectors.nlpl.eu/repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\") \n",
    "twitter_model = gensim.downloader.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `fasttext-wiki-news-subwords-300` model from the gensim repo https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetition of 3.3 to 3.7 using the fast model\n",
    "# Tokenization has been done in 3.2 so will reuse that code \n",
    "# phrase_token_vector = [nltk.tokenize.word_tokenize(i) for i in phrases]\n",
    "# emotions_and_phrases_token_vector = [nltk.tokenize.word_tokenize(i) for i in emotions_and_phrases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_list_emotions = []\n",
    "for i in phrase_token_vector:\n",
    "    mean_embedding_list_emotions.append(fast_model.get_mean_vector(i))\n",
    "\n",
    "mean_embedding_list_sentiments = []\n",
    "for i in emotions_and_phrases_token_vector:\n",
    "    mean_embedding_list_sentiments.append(fast_model.get_mean_vector(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the tokens (to get the hit rate)\n",
    "training_phrase_token, testing_phrase_token = train_test_split(\n",
    "    phrase_token_vector, train_size=0.8, test_size=0.2)\n",
    "\n",
    "training_emotions_and_phrases_token, testing_emotions_and_phrases_token = train_test_split(\n",
    "    emotions_and_phrases_token_vector, train_size=0.8, test_size=0.2)\n",
    "\n",
    "\n",
    "# Split the mean embedding list for both eomtions and sentiments (the X values)\n",
    "training_X_emotions_emb, testing_X_emotions_emb = train_test_split(\n",
    "    mean_embedding_list_emotions, train_size=0.8, test_size=0.2)\n",
    "\n",
    "training_X_sentiments_emb, testing_X_sentiments_emb = train_test_split(\n",
    "    mean_embedding_list_sentiments, train_size=0.8, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit Rate for phrases training set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in training_phrase_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            fast_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in training set (phrases) = {num_of_hits/total*100}%\")\n",
    "\n",
    "\n",
    "# Hit Rate for phrases testing set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in testing_phrase_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            fast_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in testing set (phrases) = {num_of_hits/total*100}%\")\n",
    "\n",
    "# Hit Rate for phrases and emotions training set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in training_emotions_and_phrases_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            fast_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in training set (phrases and emotions) = {num_of_hits/total*100}%\")\n",
    "\n",
    "\n",
    "# Hit Rate for phrases and emotions testing set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in testing_emotions_and_phrases_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            fast_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in testing set (phrases and emotions) = {num_of_hits/total*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For emotions classification\n",
    "emotions_classifier_mlp_embedding = MLPClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_mlp_embedding.fit(X=training_X_emotions_emb,\n",
    "                                      y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction_mlp_embedding = emotions_classifier_mlp_embedding.predict(\n",
    "    X=testing_X_emotions_emb)\n",
    "print(emotion_prediction_mlp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Emotions results\n",
    "performance_file = open(\"performance_3.8\", \"w\")\n",
    "performance_file.write(\n",
    "    \"-----Emotions classification (fast model) (Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_mlp_embedding.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp_embedding)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp_embedding, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sentiments classification\n",
    "sentiments_classifier_mlp_embedding = MLPClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "sentiments_classifier_mlp_embedding.fit(X=training_X_sentiments_emb,\n",
    "                                      y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "sentiments_prediction_mlp_embedding = sentiments_classifier_mlp_embedding.predict(\n",
    "    X=testing_X_sentiments_emb)\n",
    "print(sentiments_prediction_mlp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_3.8\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (concept model) (Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiments_classifier_mlp_embedding.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_prediction_mlp_embedding)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_prediction_mlp_embedding, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Twitter (`glove-twitter-100`) Model from the gensim repo https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetition of 3.3 to 3.7 using the twitter model\n",
    "# Tokenization has been done in 3.2 so will reuse that code \n",
    "# phrase_token_vector = [nltk.tokenize.word_tokenize(i) for i in phrases]\n",
    "# emotions_and_phrases_token_vector = [nltk.tokenize.word_tokenize(i) for i in emotions_and_phrases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_list_emotions = []\n",
    "for i in phrase_token_vector:\n",
    "    mean_embedding_list_emotions.append(twitter_model.get_mean_vector(i))\n",
    "\n",
    "mean_embedding_list_sentiments = []\n",
    "for i in emotions_and_phrases_token_vector:\n",
    "    mean_embedding_list_sentiments.append(twitter_model.get_mean_vector(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the tokens (to get the hit rate)\n",
    "training_phrase_token, testing_phrase_token = train_test_split(\n",
    "    phrase_token_vector, train_size=0.8, test_size=0.2)\n",
    "\n",
    "training_emotions_and_phrases_token, testing_emotions_and_phrases_token = train_test_split(\n",
    "    emotions_and_phrases_token_vector, train_size=0.8, test_size=0.2)\n",
    "\n",
    "\n",
    "# Split the mean embedding list for both eomtions and sentiments (the X values)\n",
    "training_X_emotions_emb, testing_X_emotions_emb = train_test_split(\n",
    "    mean_embedding_list_emotions, train_size=0.8, test_size=0.2)\n",
    "\n",
    "training_X_sentiments_emb, testing_X_sentiments_emb = train_test_split(\n",
    "    mean_embedding_list_sentiments, train_size=0.8, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit Rate for phrases training set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in training_phrase_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            twitter_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in training set (phrases) = {num_of_hits/total*100}%\")\n",
    "\n",
    "\n",
    "# Hit Rate for phrases testing set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in testing_phrase_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            twitter_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in testing set (phrases) = {num_of_hits/total*100}%\")\n",
    "\n",
    "# Hit Rate for phrases and emotions training set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in training_emotions_and_phrases_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            twitter_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in training set (phrases and emotions) = {num_of_hits/total*100}%\")\n",
    "\n",
    "\n",
    "# Hit Rate for phrases and emotions testing set\n",
    "num_of_hits = 0\n",
    "total = 0\n",
    "\n",
    "for i in testing_emotions_and_phrases_token:\n",
    "    for word in i:\n",
    "        try:\n",
    "            # pdb.set_trace()\n",
    "            twitter_model.key_to_index[word]\n",
    "            num_of_hits += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        total += 1\n",
    "\n",
    "print(f\"Hit Rate in testing set (phrases and emotions) = {num_of_hits/total*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For emotions classification\n",
    "emotions_classifier_mlp_embedding = MLPClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "emotions_classifier_mlp_embedding.fit(X=training_X_emotions_emb,\n",
    "                                      y=training_dataset[:, 1])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "emotion_prediction_mlp_embedding = emotions_classifier_mlp_embedding.predict(\n",
    "    X=testing_X_emotions_emb)\n",
    "print(emotion_prediction_mlp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Emotions results\n",
    "performance_file = open(\"performance_3.8\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Emotions classification (twitter model) (Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Emotions hyperparameters = {emotions_classifier_mlp_embedding.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp_embedding)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 1], y_pred=emotion_prediction_mlp_embedding, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sentiments classification\n",
    "sentiments_classifier_mlp_embedding = MLPClassifier()\n",
    "\n",
    "# Fit the model with training_X as X and columns of training_dataset as y\n",
    "sentiments_classifier_mlp_embedding.fit(X=training_X_sentiments_emb,\n",
    "                                      y=training_dataset[:, 2])\n",
    "\n",
    "# Make predictions with testing_X as X\n",
    "sentiments_prediction_mlp_embedding = sentiments_classifier_mlp_embedding.predict(\n",
    "    X=testing_X_sentiments_emb)\n",
    "print(sentiments_prediction_mlp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiments results\n",
    "performance_file = open(\"performance_3.8\", \"a\")\n",
    "performance_file.write(\n",
    "    \"-----Sentiments classification (twitter model) (Multi Layered Perception with word Embeddings)-----\\n\")\n",
    "\n",
    "performance_file.write(\n",
    "    f\"Sentiments hyperparameters = {sentiments_classifier_mlp_embedding.n_features_in_}\\n\")\n",
    "\n",
    "confusion_matrix_output = confusion_matrix(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_prediction_mlp_embedding)\n",
    "performance_file.write(f\"Confusion Matrix = \\n{confusion_matrix_output}\\n\\n\")\n",
    "\n",
    "class_report = classification_report(\n",
    "    y_true=testing_dataset[:, 2], y_pred=sentiments_prediction_mlp_embedding, zero_division=0)\n",
    "performance_file.write(f\"Classification Report = \\n{class_report}\\n\")\n",
    "performance_file.write(\n",
    "    f\"----------------------------------------------------------\\n\\n\")\n",
    "\n",
    "performance_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "820d776940a02930c69820a8cec178404e4e9e60b6116e2717a21913b50566a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
